{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a852bf",
   "metadata": {},
   "source": [
    "# This notebook assigns classes to the HSC objects with catalog cross matching\n",
    "\n",
    "You will need the HSC DR3 object catalogs.  To get clean objects in the Deep/UltraDeep fields, use the SQL query below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5060d40",
   "metadata": {},
   "source": [
    "-- Note that in practice you should not use the pixelflags marked by /**/  \n",
    "-- in searching deep/udeep fields though they are useful in wide fields.  \n",
    "-- In fact, the longer the total exposure time is,  \n",
    "-- the more likely pixels are affected by clipping, cosmic rays, and interpolation.  \n",
    "-- If you exclude objects affected by these things in deep/udeep fields,  \n",
    "-- you will miss many wanted objects.  \n",
    "\n",
    "SELECT  \n",
    "        object_id  \n",
    "      , ra  \n",
    "      , dec  \n",
    "      , g_cmodel_mag  \n",
    "      , g_cmodel_magerr  \n",
    "      , r_cmodel_mag  \n",
    "      , r_cmodel_magerr  \n",
    "      , i_cmodel_mag  \n",
    "      , i_cmodel_magerr  \n",
    "      , z_cmodel_mag  \n",
    "      , z_cmodel_magerr  \n",
    "      , y_cmodel_mag  \n",
    "      , y_cmodel_magerr  \n",
    "      , g_psfflux_mag  \n",
    "      , g_psfflux_magerr   \n",
    "      , r_psfflux_mag  \n",
    "      , r_psfflux_magerr  \n",
    "      , i_psfflux_mag  \n",
    "      , i_psfflux_magerr  \n",
    "      , z_psfflux_mag  \n",
    "      , z_psfflux_magerr  \n",
    "      , y_psfflux_mag  \n",
    "      , y_psfflux_magerr  \n",
    "      , a_g  \n",
    "      , a_r  \n",
    "      , a_i  \n",
    "      , a_z  \n",
    "      , a_y  \n",
    "    FROM  \n",
    "        pdr3_dud_rev.forced  \n",
    "        JOIN pdr3_dud_rev.forced2 USING (object_id)  \n",
    "    WHERE  \n",
    "        isprimary  \n",
    "    AND NOT g_sdsscentroid_flag  \n",
    "    AND NOT r_sdsscentroid_flag  \n",
    "    AND NOT i_sdsscentroid_flag  \n",
    "    AND NOT z_sdsscentroid_flag  \n",
    "    AND NOT y_sdsscentroid_flag  \n",
    "    AND NOT g_pixelflags_edge  \n",
    "    AND NOT r_pixelflags_edge  \n",
    "    AND NOT i_pixelflags_edge  \n",
    "    AND NOT z_pixelflags_edge  \n",
    "    AND NOT y_pixelflags_edge  \n",
    "    --AND NOT g_pixelflags_interpolatedcenter /**/  \n",
    "    --AND NOT r_pixelflags_interpolatedcenter /**/  \n",
    "    --AND NOT i_pixelflags_interpolatedcenter /**/  \n",
    "    --AND NOT z_pixelflags_interpolatedcenter /**/  \n",
    "    --AND NOT y_pixelflags_interpolatedcenter /**/  \n",
    "    AND NOT g_pixelflags_saturatedcenter  \n",
    "    AND NOT r_pixelflags_saturatedcenter  \n",
    "    AND NOT i_pixelflags_saturatedcenter  \n",
    "    AND NOT z_pixelflags_saturatedcenter  \n",
    "    AND NOT y_pixelflags_saturatedcenter  \n",
    "    --AND NOT g_pixelflags_crcenter /**/  \n",
    "    --AND NOT r_pixelflags_crcenter /**/  \n",
    "    --AND NOT i_pixelflags_crcenter /**/   \n",
    "    --AND NOT z_pixelflags_crcenter /**/  \n",
    "    --AND NOT y_pixelflags_crcenter /**/  \n",
    "    AND NOT g_pixelflags_bad  \n",
    "    AND NOT r_pixelflags_bad  \n",
    "    AND NOT i_pixelflags_bad  \n",
    "    AND NOT z_pixelflags_bad  \n",
    "    AND NOT y_pixelflags_bad  \n",
    "    AND NOT g_cmodel_flag  \n",
    "    AND NOT r_cmodel_flag  \n",
    "    AND NOT i_cmodel_flag  \n",
    "    AND NOT z_cmodel_flag  \n",
    "    AND NOT y_cmodel_flag  \n",
    ";  \n",
    "\n",
    "-- * Flags pixelflags_* vs. pixelflags_*center  \n",
    "--   \"any\" (without \"center\") flags are set when any of the pixels in the object's  \n",
    "--   footprint is bad. The critera \"NOT pixelflags_*\" are too strict. Since most of  \n",
    "--   the object's flux comes from its center, it is usually safe to accept bad  \n",
    "--   conditions in the outskirt of the object.  \n",
    "--  \n",
    "-- * Condition \"isprimary\" is true  \n",
    "--   - no children  \n",
    "--   - in the inner region of a coadd patch (detect_ispatchinner)  \n",
    "--   - in the inner region of a coadd tract (detect_istractinner)  \n",
    "--   - not \"detected\" in a pseudo-filter (see config.pseudoFilterList)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you need to point to pre-existing scarlet install\n",
    "import sys\n",
    "#sys.path.insert(1, '/home/g4merz/deblend/astrodet/')\n",
    "#sys.path.insert(1, '/home/paleo2/.conda/envs/astro-det-scarlet2/lib/python3.7/site-packages/scarlet-1.0.1+gfde109a-py3.7-linux-ppc64le.egg/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c437394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import scarlet\n",
    "import sep\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from scipy import stats as scistats\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import astropy.io.fits as fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.stats import gaussian_fwhm_to_sigma\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "from scarlet.display import AsinhMapping\n",
    "from astropy.nddata import Cutout2D\n",
    "\n",
    "# Astrodet imports\n",
    "import astrodet.scarlet_catalog as sc\n",
    "#import astrodet.scarlet as sc\n",
    "from astrodet.hsc import get_tract_patch_from_coord, get_hsc_data#, get_hsc_DR3_data\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.structures import BoxMode\n",
    "import cv2\n",
    "\n",
    "from astrodet import astrodet as toolkit\n",
    "\n",
    "\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "#matplotlib.rc('image', cmap='gray', interpolation='none', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d443005",
   "metadata": {},
   "source": [
    "\n",
    "Make a list of sky coords of every source in every scarlet image and turn into astropy SkyCoord (catalog)  \n",
    "\n",
    "Grab the HSC catalogs and make a SkyCoord list(c)  \n",
    "\n",
    "Search for matches within 1'' using  `astropy search_around_sky()`\n",
    "\n",
    "Use indices to set class of scarlet catalog objects from extendedness of each HSC catalog object  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f0569c",
   "metadata": {},
   "source": [
    "## Load in the HSC object catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8120496",
   "metadata": {},
   "outputs": [],
   "source": [
    "dall=pd.read_csv('/home/g4merz/deblend/data/all_cat_mags_primary.csv.gz')\n",
    "ra_all = dall['ra'][:].values\n",
    "dec_all = dall['dec'][:].values\n",
    "allcatalog = SkyCoord(ra=ra_all*u.degree, dec=dec_all*u.degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d1025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82e499f3",
   "metadata": {},
   "source": [
    "## The functions below will return the image cutouts and their coordinates.  \n",
    "This lets us calculate the coordinates of each object and then cross match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(datas, normalize='lupton', stretch=5, Q=10, m=0, ceil_percentile=99.995, dtype=np.uint8):\n",
    "    # Read image\n",
    "    \n",
    "    g = datas[0]\n",
    "    r = datas[1]\n",
    "    z = datas[2]\n",
    "    \n",
    "    # Contrast scaling / normalization\n",
    "    I = (z + r + g)/3.0\n",
    "    \n",
    "    length, width = g.shape\n",
    "    image = np.empty([length, width, 3], dtype=dtype)\n",
    "    \n",
    "    # Options for contrast scaling\n",
    "    if normalize.lower() == 'lupton':\n",
    "        z = z*np.arcsinh(stretch*Q*(I - m))/(Q*I)\n",
    "        r = r*np.arcsinh(stretch*Q*(I - m))/(Q*I)\n",
    "        g = g*np.arcsinh(stretch*Q*(I - m))/(Q*I)\n",
    "    elif normalize.lower() == 'zscore':\n",
    "        Isigma = I*np.mean([np.nanstd(g), np.nanstd(r), np.nanstd(z)])\n",
    "        z = (z - np.nanmean(z) - m)/Isigma\n",
    "        r = (r - np.nanmean(r) - m)/Isigma\n",
    "        g = (g - np.nanmean(g) - m)/Isigma\n",
    "    elif normalize.lower() == 'linear':\n",
    "        z = (z - m)/I\n",
    "        r = (r - m)/I\n",
    "        g = (g - m)/I\n",
    "    else:\n",
    "        print('Normalize keyword not recognized.')\n",
    "\n",
    "    max_RGB = np.nanpercentile([z, r, g], ceil_percentile)\n",
    "    # avoid saturation\n",
    "    r = r/max_RGB; g = g/max_RGB; z = z/max_RGB\n",
    "\n",
    "    # Rescale to 0-255 for dtype=np.uint8\n",
    "    max_dtype = np.iinfo(dtype).max\n",
    "    r = r*max_dtype\n",
    "    g = g*max_dtype\n",
    "    z = z*max_dtype\n",
    "\n",
    "    # 0-255 RGB image\n",
    "    image[:,:,0] = z # R\n",
    "    image[:,:,1] = r # G\n",
    "    image[:,:,2] = g # B\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hsc_DR3_data(dirpath, filters=['g','r','i'], tract=10054, patch=[0,0], coord=None, cutout_size=[128, 128]):\n",
    "    \"\"\"\n",
    "    Get HSC data given tract/patch info or SkyCoord\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dirpath : str\n",
    "        Path to HSC image file directory\n",
    "    filters : list \n",
    "        A list of filters for your images. Default is ['g', 'r', 'i'].\n",
    "    tract  : int\n",
    "        An integer used for specifying the tract. Default is 10054\n",
    "    patch : [int, int]\n",
    "        Patch #,#. Default is [0,0]\n",
    "    coord  : SkyCoord\n",
    "        Astropy SkyCoord, when specified, overrides tract/patch info and attempts to lookup HSC filename from ra, dec. \n",
    "        Default is None\n",
    "    cutout_size: [int, int]\n",
    "        Size of cutout to use (set to None for no cutting). Default is [128, 128]\n",
    "        \n",
    "    The image filepath is in the form:\n",
    "        {dirpath}/deepCoadd/HSC-{filter}/{tract}/{patch[0]},{patch[1]}/calexp-HSC-{filter}-{tract}-{patch[0]},{patch[1]}.fits\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data : ndarray\n",
    "        HSC data array with dimensions [filters, N, N]\n",
    "    \"\"\"\n",
    "    \n",
    "    filters = [f.upper() for f in filters]\n",
    "    \n",
    "    #if coord is not None:\n",
    "    #    print(\"Overriding tract/patch info and looking for HSC file at requested coordinates.\")\n",
    "    #    tract, patch = get_tract_patch_from_coord(coord)\n",
    "        \n",
    "    datas = []\n",
    "\n",
    "    for f in filters:\n",
    "        filepath = os.path.join(dirpath, f'HSC-{f}/calexp-HSC-{f}-{tract}-{patch[0]},{patch[1]}.fits')\n",
    "        \n",
    "        #print(f'Loading \"{filepath}\".')\n",
    "        #try:\n",
    "        \n",
    "        with fits.open(filepath) as obs_hdul:\n",
    "        #obs_hdul = fits.open(filepath)\n",
    "            data = obs_hdul[1].data\n",
    "            wcs = WCS(obs_hdul[1].header)\n",
    "        \n",
    "        cutout =None\n",
    "        \n",
    "        # Cutout data at center of patch (coord=None) or at coord (if specified)\n",
    "        if cutout_size is not None:\n",
    "            # Use coord for center position if specified\n",
    "            if coord is None:\n",
    "                shape = np.shape(data)\n",
    "                position = (shape[0]/2, shape[1]/2)\n",
    "            else:\n",
    "                position = coord\n",
    "            #data = Cutout2D(data, position=position, size=cutout_size, wcs=wcs).data\n",
    "            cutout = Cutout2D(data, position=position, size=cutout_size, wcs=wcs)\n",
    "            data = cutout.data\n",
    "\n",
    "        datas.append(data)\n",
    "        #except:\n",
    "        #    print('Missing filter ', f)\n",
    "            \n",
    "\n",
    "    return np.array(datas), cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced94453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers(sub_shape):\n",
    "    centers=[]\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            #print(sub_shape[1]*i)\n",
    "            s=np.array(sub_shape)/2 + (sub_shape[0]*j, sub_shape[1]*i)\n",
    "            centers.append(s)\n",
    "            \n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cutout(tract,patch,sp,plot=True):\n",
    "\n",
    "    nblocks=4\n",
    "    nfilters=3\n",
    "    \n",
    "    #Loading \"/home/g4merz/deblend/data/raw_HSC_DR3/HSC-G/calexp-HSC-G-8765-2,3.fits\".\n",
    "    hsc_dirpath = '/home/g4merz/deblend/data/raw_HSC_DR3/'\n",
    "\n",
    "    dat,cutout = get_hsc_DR3_data(hsc_dirpath,tract=tract,patch=patch,coord=None,cutout_size=None)\n",
    "    print(dat.shape)\n",
    "    block_size = [dat.shape[1]//nblocks, dat.shape[2]//nblocks]\n",
    "\n",
    "    datas_blocks = view_as_blocks(dat, block_shape=(nfilters, block_size[0], block_size[1]))\n",
    "    \n",
    "    sub_shape = datas_blocks.shape[-2:]\n",
    "\n",
    "    #review this code\n",
    "    centers = get_centers(sub_shape[::-1])\n",
    "    #centers = get_centers(sub_shape)\n",
    "\n",
    "    coord=centers[sp]\n",
    "\n",
    "    datsm,cutout = get_hsc_DR3_data(hsc_dirpath,tract=tract,patch=patch,coord=coord,cutout_size=sub_shape)\n",
    "    #datas_blocks = datas_blocks.reshape(nblocks**2, nfilters, block_size[0], block_size[1])\n",
    "    #datas = datas_blocks[sp,:,:,:]\n",
    "    if plot:\n",
    "        fig,ax = plt.subplots(1,2,figsize=(10,10))\n",
    "\n",
    "        ax[0].imshow(read_image(dat),origin='lower')\n",
    "        cutout.plot_on_original(ax[0],color='white')\n",
    "        ax[1].imshow(read_image(datsm),origin='lower')\n",
    "\n",
    "        #ax[0].axis('off')\n",
    "        #ax[1].axis('off')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    return cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ded1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tract=8766\n",
    "#patch = [0,0]\n",
    "#sp=1\n",
    "tract=9813\n",
    "patch=[5,4]\n",
    "sp=4\n",
    "cutout= get_cutout(tract,patch,sp,plot=True)\n",
    "#plt.savefig('/home/g4merz/deblend/plots/cutout_ex.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5cfe43",
   "metadata": {},
   "source": [
    "### Now we can return a list of RA,DEC coordinates for every detected object in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed123681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_sp_cat(filename,f='G'):\n",
    "    #im = fits.open(filename)\n",
    "    \n",
    "    with fits.open(filename) as im:\n",
    "\n",
    "        s = filename.split(f'{f}-')[1].split('.fits')[0]\n",
    "        tract, patch,sp = s.split('-')\n",
    "        tract = int(tract)\n",
    "        patch = tuple(map(int, patch.split(',')))\n",
    "        sp = int(sp[1:-14])\n",
    "\n",
    "\n",
    "        cutout = get_cutout(tract,patch,sp,plot=False)\n",
    "\n",
    "        ras=[]\n",
    "        decs=[]\n",
    "\n",
    "        for source in im[1:]:\n",
    "            coords = source.header['BBOX'].split(',')\n",
    "            x = int(coords[0])\n",
    "            y = int(coords[1])\n",
    "            skycoords=cutout.wcs.pixel_to_world(x,y)\n",
    "            ras.append(skycoords.ra.degree)\n",
    "            decs.append(skycoords.dec.degree)\n",
    "            \n",
    "    return ras,decs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19759c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fi='/home/shared/hsc/HSC/HSC_DR3/data/train/G-8766-0,0-c5_scarlet_model.fits'\n",
    "maskfile='/home/shared/hsc/HSC/HSC_DR3/data/train/I-8766-0,0-c5_scarlet_segmask.fits'\n",
    "#testmask = fits.open(maskfile)\n",
    "ras,decs = return_sp_cat(fi)\n",
    "#c = SkyCoord(ra=ras*u.degree, dec=decs*u.degree)\n",
    "#idx, d2d, d3d = c.match_to_catalog_sky(allcatalog)\n",
    "#fits.close(maskfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86286ea",
   "metadata": {},
   "source": [
    "Code belwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def return_model_cat(args):\n",
    "    modpath,segpath,dirpath = args\n",
    "\n",
    "    print('Running on ', segpath)\n",
    "\n",
    "    oG,oR,oI, model = sc.return_model_objects(modpath,stringcap=14,dirpath=dirpath)\n",
    "    sources = []\n",
    "    #masks = []\n",
    "    catalogs =[]\n",
    "\n",
    "    #bkgmod = sep.Background(np.sum(model,axis=0))\n",
    "    bkgmod = sep.Background(model[0])\n",
    "    exceptions=[]\n",
    "    #for i in range(0,1):\n",
    "    for i in range(len(oG)):\n",
    "        oG_new, oR_new, oI_new = sc.return_spliced_sources(oG[i],oR[i],oI[i])\n",
    "        source = np.zeros((3,)+oG_new.shape)\n",
    "        try:\n",
    "            source[0] = oG_new\n",
    "            source[1] = oR_new\n",
    "            source[2] = oI_new\n",
    "            sources.append(source)\n",
    "        except ValueError:\n",
    "            print('Error with source ', i, 'on file ', modpath)\n",
    "            continue\n",
    "        #maskthresh = bkg_rms.mean()*5.0\n",
    "        #maskthresh = bkg.globalrms*1.2\n",
    "\n",
    "        dt = source\n",
    "\n",
    "        # Detection image as the sum over all images\n",
    "        #model_det = np.sum(dt, axis=0)\n",
    "    \n",
    "        #calculate band mag\n",
    "        model_det = source[2]\n",
    "        \n",
    "        lvl_segmask = 5.0\n",
    "        #maskthresh = 10.0\n",
    "        bkgim = sep.Background(model_det)\n",
    "        try:\n",
    "            catalog,mask = sep.extract(model_det, lvl_segmask, err=bkgmod.globalrms, segmentation_map=True)\n",
    "        except:\n",
    "            print('Exception with source %d in file ' %i, modpath)\n",
    "            exceptions.append(i)\n",
    "            mask = np.zeros_like(model_det)\n",
    "            mask[model_det>lvl_segmask*bkgmod.globalrms] = 1\n",
    "            catalog=[]\n",
    "\n",
    "        # If more than 1 source is detected for some reason (e.g. artifacts)\n",
    "        if len(catalog) > 1:\n",
    "            print('More than 1 source for object ', i, ' in file ', modpath)\n",
    "            # keep the brightest\n",
    "            idx = np.argmax([c['cflux'] for c in catalog])\n",
    "            catalog = catalog[idx]\n",
    "            mask[mask!=idx]=0\n",
    "\n",
    "        #masks.append(mask)\n",
    "        catalogs.append(catalog)\n",
    "    return catalogs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dirpath = '/home/shared/hsc/HSC/HSC_DR3/data/' # Path to dataset\n",
    "output_dir = '/home/shared/hsc/HSC/HSC_DR3/models/'\n",
    "\n",
    "dataset_names = ['train', 'test', 'val'] \n",
    "\n",
    "def get_data_from_json(file):\n",
    "    # Opening JSON file\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "datadir='/home/shared/hsc/HSC/HSC_DR3/data/'\n",
    "t0 = time.time()\n",
    "dataset_dicts = {}\n",
    "for i, d in enumerate(dataset_names):\n",
    "    print(f'Loading {d}')\n",
    "    dataset_dicts[d] = get_data_from_json(datadir+dataset_names[i]+'_sample.json')\n",
    "    \n",
    "print('Took ', time.time()-t0, 'seconds for samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d542b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_train = []\n",
    "maskfiles_train = []\n",
    "\n",
    "for d in dataset_dicts['train']:\n",
    "    filename = d['filename_G']\n",
    "    s = filename.split(f'G-')[1].split('.fits')[0]\n",
    "    tract, patch,sp = s.split('-')\n",
    "    tract = int(tract)\n",
    "    patch = tuple(map(int, patch.split(',')))\n",
    "    sp = int(sp[1:-12])\n",
    "\n",
    "    file = f'/home/shared/hsc/HSC/HSC_DR3/data/train/G-{tract}-{patch[0]},{patch[1]}-c{sp}_scarlet_model.fits'\n",
    "    maskfile = f'/home/shared/hsc/HSC/HSC_DR3/data/train/I-{tract}-{patch[0]},{patch[1]}-c{sp}_scarlet_segmask.fits'\n",
    "\n",
    "    files_train.append(file)\n",
    "    maskfiles_train.append(maskfile)\n",
    "    \n",
    "files_test = []\n",
    "maskfiles_test = []\n",
    "\n",
    "for d in dataset_dicts['test']:\n",
    "    filename = d['filename_G']\n",
    "    s = filename.split(f'G-')[1].split('.fits')[0]\n",
    "    tract, patch,sp = s.split('-')\n",
    "    tract = int(tract)\n",
    "    patch = tuple(map(int, patch.split(',')))\n",
    "    sp = int(sp[1:-12])\n",
    "\n",
    "    file = f'/home/shared/hsc/HSC/HSC_DR3/data/test/G-{tract}-{patch[0]},{patch[1]}-c{sp}_scarlet_model.fits'\n",
    "    maskfile = f'/home/shared/hsc/HSC/HSC_DR3/data/test/I-{tract}-{patch[0]},{patch[1]}-c{sp}_scarlet_segmask.fits'\n",
    "\n",
    "    files_test.append(file)\n",
    "    maskfiles_test.append(maskfile)\n",
    "\n",
    "    \n",
    "files_val = []\n",
    "maskfiles_val = []\n",
    "\n",
    "for d in dataset_dicts['val']:\n",
    "    filename = d['filename_G']\n",
    "    s = filename.split(f'G-')[1].split('.fits')[0]\n",
    "    tract, patch,sp = s.split('-')\n",
    "    tract = int(tract)\n",
    "    patch = tuple(map(int, patch.split(',')))\n",
    "    sp = int(sp[1:-12])\n",
    "\n",
    "    file = f'/home/shared/hsc/HSC/HSC_DR3/data/val/G-{tract}-{patch[0]},{patch[1]}-c{sp}_scarlet_model.fits'\n",
    "    maskfile = f'/home/shared/hsc/HSC/HSC_DR3/data/train/I-{tract}-{patch[0]},{patch[1]}-c{sp}_scarlet_segmask.fits'\n",
    "    files_val.append(file)\n",
    "    maskfiles_val.append(maskfile)\n",
    "maskfiles = [maskfiles_train,maskfiles_test,maskfiles_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d486cacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a419bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheme_2(gext,rext,iext,imag):\n",
    "    if np.isnan(gext) or np.isnan(rext) or np.isnan(iext):\n",
    "        e=np.array([gext,rext,iext])\n",
    "        bad=np.isnan(e)\n",
    "        good=~bad\n",
    "        sbad=sum(bad)\n",
    "        if sbad>=3:\n",
    "            catid =2\n",
    "        else:\n",
    "            sgood=sum(e[good])\n",
    "            if sgood>=1:\n",
    "                catid=1\n",
    "            else:\n",
    "                catid=0\n",
    "\n",
    "    else:\n",
    "        totext = gext+rext+iext\n",
    "\n",
    "        if totext>=1:\n",
    "            catid=1\n",
    "        else:\n",
    "            catid=0\n",
    "\n",
    "    return catid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fae7aa",
   "metadata": {},
   "source": [
    "###  Old class assginment scheme based on nearest object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb32b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_classes(filename,dset='train'):\n",
    "    s = filename.split(f'G-')[1].split('.fits')[0]\n",
    "    tract, patch,sp = s.split('-')\n",
    "    tract = int(tract)\n",
    "    patch = tuple(map(int, patch.split(',')))\n",
    "    sp = int(sp[1:-14])\n",
    "\n",
    "    maskfile = f'/home/shared/hsc/HSC/HSC_DR3/data/{dset}/I-{tract}-{patch[0]},{patch[1]}-c{sp}_scarlet_segmask.fits'\n",
    "    #maskfile = filename\n",
    "\n",
    "    ras,decs = return_sp_cat(filename)\n",
    "    c = SkyCoord(ra=ras*u.degree, dec=decs*u.degree)\n",
    "    idx, d2d, d3d = c.match_to_catalog_sky(allcatalog)\n",
    "\n",
    "    print('Assigning classes ', filename)\n",
    "\n",
    "\n",
    "    with fits.open(maskfile, mode='update') as hdul:\n",
    "\n",
    "    # Change something in hdul.\n",
    "\n",
    "        for i,ind in enumerate(idx):\n",
    "            ext = dall.loc[ind]\n",
    "            gext=ext['g_extendedness_value']\n",
    "            rext=ext['r_extendedness_value']\n",
    "            iext=ext['i_extendedness_value']\n",
    "            oid = dall['# object_id'][ind]\n",
    "            imag = ext['i_cmodel_mag']\n",
    "\n",
    "            #catid1 = scheme_1(gext,rext,iext,imag)\n",
    "            catid2 = scheme_2(gext,rext,iext,imag)\n",
    "            #catid3 = scheme_3(gext,rext,iext,imag)\n",
    "\n",
    "            if np.isnan(imag) or np.isinf(imag):\n",
    "                imag=0\n",
    "\n",
    "            #hdul[1+i].header.set('cat_id'+suffix,catid1)\n",
    "            hdul[1+i].header.set('cat_id2'+suffix,catid2)\n",
    "            #hdul[1+i].header.set('cat_id3'+suffix,catid3)\n",
    "            hdul[1+i].header.set('imag',imag)\n",
    "            hdul[1+i].header.set('hsc_oid',oid)\n",
    "\n",
    "\n",
    "        hdul.flush()  # changes are written back to original.fits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c86d5d",
   "metadata": {},
   "source": [
    "### New class assignment based on distance and mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a20428",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def assign_classes_new(filename,dset='train',seplim=1.0):\n",
    "    s = filename.split(f'G-')[1].split('.fits')[0]\n",
    "    tract, patch,sp = s.split('-')\n",
    "    tract = int(tract)\n",
    "    patch = tuple(map(int, patch.split(',')))\n",
    "    sp = int(sp[1:-14])\n",
    "    \n",
    "    maskfile = f'/home/shared/hsc/HSC/HSC_DR3/data/{dset}/I-{tract}-{patch[0]},{patch[1]}-c{sp}_scarlet_segmask.fits'\n",
    "    #maskfile = filename\n",
    "    \n",
    "    ras,decs = return_sp_cat(filename)\n",
    "    cats = return_model_cat((filename,maskfile,dirpath))\n",
    "    \n",
    "    c = SkyCoord(ra=ras*u.degree, dec=decs*u.degree)\n",
    "    idx, d2d, d3d = c.match_to_catalog_sky(allcatalog)\n",
    "    idxc, idxcatalog, d2ds, d3ds = allcatalog.search_around_sky(c, seplim*u.arcsec)\n",
    "    allcatalog_inds =[]     \n",
    "\n",
    "    for i,cat in enumerate(cats):\n",
    "        hsc_matches = np.where(idxc==i)[0]\n",
    "        \n",
    "        if len(cat)==0:\n",
    "            allcatalog_ind=-1\n",
    "            allcatalog_inds.append(allcatalog_ind)\n",
    "            continue\n",
    "        \n",
    "        flux = cat['cflux']\n",
    "        imag = 27-2.5*np.log10(flux)\n",
    "        hsc_imag = dall.loc[idxcatalog[hsc_matches]]['i_cmodel_mag'].values\n",
    "        \n",
    "        if hsc_matches.size==0:\n",
    "            #print('No matches at ', i, ' within one arcsecond, taking nearest neighbor')\n",
    "            print('No matches at ', i, ' within one arcsecond, remove annotation')\n",
    "            #allcatalog_ind = idx[i]\n",
    "            allcatalog_ind=-1\n",
    "            allcatalog_inds.append(allcatalog_ind)\n",
    "            continue\n",
    "\n",
    "        if imag.size==0:\n",
    "            #allcatalog_ind = idx[i]\n",
    "            allcatalog_ind=-1\n",
    "            allcatalog_inds.append(allcatalog_ind)\n",
    "            continue\n",
    "            \n",
    "        magdiffs = abs(np.subtract(imag,hsc_imag))\n",
    "\n",
    "        if np.isnan(magdiffs).any():\n",
    "            #print('NaN mag in HSC catalog, taking nearest neighbor')\n",
    "            print('NaN mag in HSC catalog, skipping annotation')\n",
    "            #allcatalog_ind = idx[i]\n",
    "            allcatalog_ind=-1\n",
    "            allcatalog_inds.append(allcatalog_ind)\n",
    "            continue\n",
    "\n",
    "        indmin = np.argmin(magdiffs)\n",
    "\n",
    "        if magdiffs[indmin]>1:\n",
    "            #print(f'Magnitude difference is greater than 1 at {i}, taking nearest neighbor')\n",
    "            print(f'Magnitude difference is greater than 1 at {i}, skipping annotation')\n",
    "\n",
    "            #allcatalog_ind = idx[i]\n",
    "            allcatalog_ind=-1\n",
    "            allcatalog_inds.append(allcatalog_ind)\n",
    "            continue\n",
    "        \n",
    "\n",
    "        allcatalog_ind = idxcatalog[hsc_matches[indmin]]\n",
    "        allcatalog_inds.append(allcatalog_ind)\n",
    "\n",
    "\n",
    "    with fits.open(maskfile, mode='update') as hdul:\n",
    "\n",
    "    # Change something in hdul.\n",
    "   \n",
    "        for i,ind in enumerate(allcatalog_inds):\n",
    "            if ind ==-1:\n",
    "                catid=-1\n",
    "            \n",
    "            else:\n",
    "                ext = dall.loc[ind]\n",
    "                gext=ext['g_extendedness_value']\n",
    "                rext=ext['r_extendedness_value']\n",
    "                iext=ext['i_extendedness_value']\n",
    "                zext=ext['z_extendedness_value']\n",
    "                yext=ext['y_extendedness_value']\n",
    "                imag = ext['i_cmodel_mag']\n",
    "                \n",
    "                catid = scheme_2(gext,rext,iext,imag)\n",
    "                if catid==2:\n",
    "                    print('Other at ', i)\n",
    "\n",
    "            hdul[1+i].header.set('test_id',catid)\n",
    "            \n",
    "            #hdul[1+i].header.set('cat_id3',catid3)\n",
    "\n",
    "        hdul.flush()  # changes are written back to original.fits\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04491f22",
   "metadata": {},
   "source": [
    "## Run and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#want to test on a subpatch that is completely covered by HST catalog\n",
    "dirpath ='/home/shared/hsc/HSC/HSC_DR3/data/train/'\n",
    "dset='train'\n",
    "qind=669\n",
    "\n",
    "d2ds=assign_classes_new(files_train[qind],dset=dset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd0f83",
   "metadata": {},
   "source": [
    "Now that we have the classes assigned, we can visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf862f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sd=[]\n",
    "filenames_dict_single = {}\n",
    "filenames_dict_single['filters'] = ['g', 'r', 'i']\n",
    "for f in filenames_dict_single['filters']:\n",
    "    filenames_dict_single[f] = {}\n",
    "    # List of image files in the dataset\n",
    "    #Yufeng dec/21  [Errno 2] No such file or directory: '/home/shared/hsc/test/G-I-8525-4,5-c5_scarlet_img'\n",
    "    #filenames_dict[f]['img'] = [os.path.join(data_path, f'{f.upper()}-{tract_patch}_scarlet_img.fits') for tract_patch in s]\n",
    "    #Yufeng jan 18 f.upper() indicates filter, tract_patch[1:] removes the default I band in the front\n",
    "    filenames_dict_single[f]['img'] = [dataset_dicts[dset][qind]['filename_%s' %f.upper()]]\n",
    "    # List of mask files in the dataset\n",
    "    #Yufeng jan 18 all mask files are in the I band\n",
    "    filenames_dict_single[f]['mask'] = [maskfiles_train[qind]]\n",
    "sd.append(filenames_dict_single)\n",
    "print(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_astro_dicts(filename_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    This needs to be customized to your training data format\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    dataset_dicts = []\n",
    "    filters = list(filename_dict.keys())\n",
    "    #yufeng april5: why only 1st filter\n",
    "    f = filename_dict['filters'][0] # Pick the 1st filter for now\n",
    "    \n",
    "    # Filename loop\n",
    "    for idx, (filename_img, filename_mask) in enumerate(zip(filename_dict[f]['img'], filename_dict[f]['mask'])):\n",
    "        record = {}\n",
    "\n",
    "        # Open FITS image of first filter (each should have same shape)\n",
    "        with fits.open(filename_img, memmap=False, lazy_load_hdus=False) as hdul:\n",
    "            height, width = hdul[0].data.shape\n",
    "            \n",
    "        # Open each FITS mask image\n",
    "        with fits.open(filename_mask, memmap=False, lazy_load_hdus=False) as hdul:\n",
    "            hdul = hdul[1:]\n",
    "            sources = len(hdul)\n",
    "            # Normalize data\n",
    "            data = [hdu.data for hdu in hdul]\n",
    "            #category_ids = [hdu.header[\"HST_ID\"] for hdu in hdul]\n",
    "            #category_ids = [hdu.header[\"CAT_ID2p\"] for hdu in hdul]\n",
    "            category_ids = [hdu.header[\"CAT_ID2p\"] for hdu in hdul]\n",
    "            \n",
    "            ellipse_pars = [hdu.header[\"ELL_PARM\"] for hdu in hdul]\n",
    "            bbox = [list(map(int, hdu.header[\"BBOX\"].split(','))) for hdu in hdul]\n",
    "            area = [hdu.header[\"AREA\"] for hdu in hdul]\n",
    "\n",
    "        # Add image metadata to record (should be the same for each filter)\n",
    "        for f in filename_dict['filters']:\n",
    "            record[f\"filename_{f.upper()}\"] = filename_dict[f]['img'][idx]\n",
    "        # Assign file_name\n",
    "        record[f\"file_name\"] = filename_dict[filename_dict['filters'][0]]['img'][idx]\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        objs = []\n",
    "\n",
    "        # Generate segmentation masks from model\n",
    "        for i in range(sources):\n",
    "            image = data[i]\n",
    "            # Why do we need this?\n",
    "            if len(image.shape) != 2:\n",
    "                print(i,'check')\n",
    "                continue\n",
    "            height_mask, width_mask = image.shape\n",
    "            # Create mask from threshold\n",
    "            mask = data[i]\n",
    "            # Smooth mask\n",
    "            #mask = cv2.GaussianBlur(mask, (9,9), 2)\n",
    "            x,y,w,h = bbox[i] # (x0, y0, w, h)\n",
    "\n",
    "            # https://github.com/facebookresearch/Detectron/issues/100\n",
    "            contours, hierarchy = cv2.findContours((mask).astype(np.uint8), cv2.RETR_TREE,\n",
    "                                                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "            segmentation = []\n",
    "            for contour in contours:\n",
    "                # contour = [x1, y1, ..., xn, yn]\n",
    "                contour = contour.flatten()\n",
    "                if len(contour) > 4:\n",
    "                    contour[::2] += (x-w//2)\n",
    "                    contour[1::2] += (y-h//2)\n",
    "                    segmentation.append(contour.tolist())\n",
    "            # No valid countors\n",
    "            if len(segmentation) == 0:\n",
    "                continue\n",
    "\n",
    "            # Add to dict\n",
    "            obj = {\n",
    "                \"bbox\": [x-w//2, y-h//2, w, h],\n",
    "                \"area\": w*h,\n",
    "                \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                \"segmentation\": segmentation,\n",
    "                \"category_id\": category_ids[i],\n",
    "                \"ellipse_pars\": ellipse_pars[i]\n",
    "            }\n",
    "            objs.append(obj)\n",
    "\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "            \n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c276c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_dect_dict = get_astro_dicts(filenames_dict_single)\n",
    "print()\n",
    "print(len(single_dect_dict[0]['annotations']))\n",
    "\n",
    "print()\n",
    "anew = [ann for ann in single_dect_dict[0]['annotations'] if ann['category_id'] not in [2,-1]]\n",
    "single_dect_dict[0]['annotations'] = anew\n",
    "print(len(single_dect_dict[0]['annotations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c55262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from astrodet.visualizer import Visualizer\n",
    "\n",
    "nsample=1\n",
    "q=0\n",
    "\n",
    "fig = plt.figure(figsize=(30,30*nsample))\n",
    "filenames = [single_dect_dict[0]['filename_G'],single_dect_dict[0]['filename_R'],single_dect_dict[0]['filename_I']]\n",
    "print(filenames)\n",
    "\n",
    "img = toolkit.read_image_hsc(filenames, normalize=\"astrolupton\", stretch=0.5, Q=10)\n",
    "visualizer = Visualizer(img,instance_mode=ColorMode.SEGMENTATION)#,metadata=MetadataCatalog.get(\"astro_train\").set(thing_classes=[\"star\", \"galaxy\",\"other\"]))\n",
    "gt_boxes = np.array([a['bbox'] for a in single_dect_dict[0]['annotations']])\n",
    "labels = np.array([a['category_id'] for a in single_dect_dict[0]['annotations']])\n",
    "labels_names = []\n",
    "for j,label in enumerate(labels):\n",
    "    if label==0:\n",
    "        labels_names.append(\"star %d\" %j)\n",
    "        #labels_names.append('star')\n",
    "    elif label==1:\n",
    "        labels_names.append(\"gal %d\" %j)\n",
    "        #labels_names.append('galaxy')\n",
    "    elif label==2:\n",
    "        labels_names.append(\"bad fit\")\n",
    "    elif label==-1:\n",
    "        labels_names.append(\"unknown %d\" %j)\n",
    "# Convert to the mode visualizer expects\n",
    "gt_boxes = BoxMode.convert(gt_boxes, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n",
    "\n",
    "#out = visualizer.draw_dataset_dict(single_dect_dict[0])\n",
    "out = visualizer.overlay_instances(boxes=gt_boxes,labels=labels_names)\n",
    "#out = visualizer.draw_dataset_dict(single_dect_dict[0],lf=True,boxf=True,alpha=0.01, ls='-')\n",
    "\n",
    "ax1 = plt.subplot(1, 1, 2*q+1)\n",
    "ax1.imshow(out.get_image())\n",
    "ax1.axis('off')\n",
    "#ax2 = plt.subplot(nsample*2, 1, 2*i+2)\n",
    "#ax2.imshow(img,origin='lower')\n",
    "#plt.savefig('/home/g4merz/deblend/plots/fullbox.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce98742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-deepdisc]",
   "language": "python",
   "name": "conda-env-.conda-deepdisc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
